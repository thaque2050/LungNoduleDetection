{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LUNG NODULE IDENTIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import rawpy\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import SimpleITK as sltk\n",
    "import matplotlib.animation as animation\n",
    "import imageio\n",
    "import cv2\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "import multiprocessing\n",
    "import glob\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nodule Annotation File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/export/data/phddata/thaque/'\n",
    "#path='D:/Data Science Bowl 2017/LUNA Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seriesuid</th>\n",
       "      <th>coordX</th>\n",
       "      <th>coordY</th>\n",
       "      <th>coordZ</th>\n",
       "      <th>diameter_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>-128.699421</td>\n",
       "      <td>-175.319272</td>\n",
       "      <td>-298.387506</td>\n",
       "      <td>5.651471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>103.783651</td>\n",
       "      <td>-211.925149</td>\n",
       "      <td>-227.121250</td>\n",
       "      <td>4.224708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100398138793...</td>\n",
       "      <td>69.639017</td>\n",
       "      <td>-140.944586</td>\n",
       "      <td>876.374496</td>\n",
       "      <td>5.786348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n",
       "      <td>-24.013824</td>\n",
       "      <td>192.102405</td>\n",
       "      <td>-391.081276</td>\n",
       "      <td>8.143262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n",
       "      <td>2.441547</td>\n",
       "      <td>172.464881</td>\n",
       "      <td>-405.493732</td>\n",
       "      <td>18.545150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           seriesuid      coordX      coordY  \\\n",
       "0  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222... -128.699421 -175.319272   \n",
       "1  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...  103.783651 -211.925149   \n",
       "2  1.3.6.1.4.1.14519.5.2.1.6279.6001.100398138793...   69.639017 -140.944586   \n",
       "3  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...  -24.013824  192.102405   \n",
       "4  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...    2.441547  172.464881   \n",
       "\n",
       "       coordZ  diameter_mm  \n",
       "0 -298.387506     5.651471  \n",
       "1 -227.121250     4.224708  \n",
       "2  876.374496     5.786348  \n",
       "3 -391.081276     8.143262  \n",
       "4 -405.493732    18.545150  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(path+'CSVFILES/annotations.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Positive Reduction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seriesuid</th>\n",
       "      <th>coordX</th>\n",
       "      <th>coordY</th>\n",
       "      <th>coordZ</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>68.420000</td>\n",
       "      <td>-74.480000</td>\n",
       "      <td>-288.700000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>-95.209361</td>\n",
       "      <td>-91.809406</td>\n",
       "      <td>-377.426350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>-24.766755</td>\n",
       "      <td>-120.379294</td>\n",
       "      <td>-273.361539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>-63.080000</td>\n",
       "      <td>-65.740000</td>\n",
       "      <td>-344.240000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>52.946688</td>\n",
       "      <td>-92.688873</td>\n",
       "      <td>-241.067872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           seriesuid     coordX      coordY  \\\n",
       "0  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...  68.420000  -74.480000   \n",
       "1  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222... -95.209361  -91.809406   \n",
       "2  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222... -24.766755 -120.379294   \n",
       "3  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222... -63.080000  -65.740000   \n",
       "4  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...  52.946688  -92.688873   \n",
       "\n",
       "       coordZ  class  \n",
       "0 -288.700000      0  \n",
       "1 -377.426350      0  \n",
       "2 -273.361539      0  \n",
       "3 -344.240000      0  \n",
       "4 -241.067872      0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(path+'CSVFILES/candidates_V2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    753418\n",
       "1      1557\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset is highly imbalanced\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seriesuid</th>\n",
       "      <th>coordX</th>\n",
       "      <th>coordY</th>\n",
       "      <th>coordZ</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>-128.6</td>\n",
       "      <td>-175.3</td>\n",
       "      <td>-298.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>103.7</td>\n",
       "      <td>-211.9</td>\n",
       "      <td>-227.1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100398138793...</td>\n",
       "      <td>69.6</td>\n",
       "      <td>-140.9</td>\n",
       "      <td>876.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>192.1</td>\n",
       "      <td>-391.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>172.4</td>\n",
       "      <td>-405.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           seriesuid  coordX  coordY  coordZ  \\\n",
       "0  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...  -128.6  -175.3  -298.3   \n",
       "1  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...   103.7  -211.9  -227.1   \n",
       "2  1.3.6.1.4.1.14519.5.2.1.6279.6001.100398138793...    69.6  -140.9   876.3   \n",
       "3  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...   -24.0   192.1  -391.0   \n",
       "4  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...     2.4   172.4  -405.4   \n",
       "\n",
       "   probability  \n",
       "0          1.0  \n",
       "1          0.8  \n",
       "2          0.2  \n",
       "3          0.5  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv(path+'CSVFILES/sampleSubmission.csv')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling image to isometric form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scan may have a pixel spacing of [2.5, 0.5, 0.5], which means that the distance between slices is 2.5 millimeters. For a different scan this may be [1.5, 0.725, 0.725], this can be problematic for automatic analysis (e.g. using ConvNets)! A common method of dealing with this is resampling the full dataset to a certain isotropic resolution. If we choose to resample everything to 1mm1mm1mm pixels we can use 3D convnets without worrying about learning zoom/slice thickness invariance. \n",
    "<br> -  [1] https://www.kaggle.com/akh64bit/full-preprocessing-tutorial; <br> -  [2] https://www.raddq.com/dicom-processing-segmentation-visualization-in-python/\n",
    "\n",
    "The chest scans are produced by a variety of CT scanners, this causes a difference in spacing between voxels of the original scan. We rescaled and interpolated all CT scans so that each voxel represents a 1x1x1 mm cube. <br> -  [3] https://eliasvansteenkiste.github.io/machine%20learning/lung-cancer-pred/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_image(itk_image, out_spacing=(1.0, 1.0, 1.0), is_label=False):\n",
    "    original_spacing = itk_image.GetSpacing()\n",
    "    original_size = itk_image.GetSize()\n",
    "\n",
    "    out_size = [int(np.round(original_size[0]*(original_spacing[0]/out_spacing[0]))),\n",
    "                int(np.round(original_size[1]*(original_spacing[1]/out_spacing[1]))),\n",
    "                int(np.round(original_size[2]*(original_spacing[2]/out_spacing[2])))]\n",
    "\n",
    "    resample = sltk.ResampleImageFilter()\n",
    "    resample.SetOutputSpacing(out_spacing)\n",
    "    resample.SetSize(out_size)\n",
    "    resample.SetOutputDirection(itk_image.GetDirection())\n",
    "    resample.SetOutputOrigin(itk_image.GetOrigin())\n",
    "    resample.SetTransform(sltk.Transform())\n",
    "    resample.SetDefaultPixelValue(itk_image.GetPixelIDValue())\n",
    "\n",
    "    if is_label:\n",
    "        resample.SetInterpolator(sltk.sitkNearestNeighbor)\n",
    "    else:\n",
    "        resample.SetInterpolator(sltk.sitkBSpline)\n",
    "\n",
    "    return resample.Execute(itk_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Binary Mask and Crop Region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "888"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a list of all CT scans in a folder\n",
    "L=[]\n",
    "for i in range(0,10):\n",
    "    M=[]\n",
    "    M=glob.glob(path+'subset'+str(i)+'/subset'+str(i)+'/*.mhd')\n",
    "    L=L+M\n",
    "len(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "830"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=L[0:830]\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove scans that have too many nodules as the tensor runs out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data=[]\n",
    "number_nodules=[]\n",
    "for i in range(0,len(train_data)):\n",
    "    a=train_data[i].split('/')[len(train_data[i].split('/'))-1][:-4]\n",
    "    sub_loop=len(df1[df1['seriesuid']==a])\n",
    "    \n",
    "    if (sub_loop<7):\n",
    "        number_nodules.append(sub_loop)\n",
    "        new_train_data.append(train_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "820"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to convert images to arrays, generate related mask, and split scans into smaller slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(file_list,start,end,size_split,min_slices_per_batch):\n",
    "    \n",
    "    '''\n",
    "    file_list represent the list of the location of files on the drive\n",
    "    start - represents the start index of picking the files from the file list\n",
    "    end - represents the end index of picking the files from the file list\n",
    "    split_size - represents the size of slices to be carved out of image\n",
    "    min_slides_per_scan - represents the minimum slices of the image to be included in training; first slice with lung nodules are included and the remaining slices are filled with empty slices\n",
    "    '''\n",
    "    \n",
    "    cropped_mask=[]\n",
    "    cropped_image=[]\n",
    "    \n",
    "    for i in range(start,end):\n",
    "        a=file_list[i].split('/')[len(file_list[i].split('/'))-1][:-4]\n",
    "        \n",
    "        nda0=sltk.ReadImage(file_list[i])\n",
    "        nda1=resample_image(nda0)\n",
    "        nda=sltk.GetArrayFromImage(nda1)\n",
    "        \n",
    "        #nda=(nda-nda.min())/(nda.max()-nda.min())*255\n",
    "    \n",
    "        AA = np.zeros((nda.shape[0],nda.shape[1], nda.shape[2]),dtype=int)\n",
    "    \n",
    "        X_org=np.array(nda1.GetOrigin())[0]\n",
    "        Y_org=np.array(nda1.GetOrigin())[1]\n",
    "        Z_org=np.array(nda1.GetOrigin())[2]\n",
    "    \n",
    "        sub_loop=len(df1[df1['seriesuid']==a])\n",
    "                \n",
    "        for w in range(0,sub_loop):\n",
    "            radius = int(df1[df1['seriesuid']==a]['diameter_mm'].iloc[w]/2)\n",
    "            x0=df1[df1['seriesuid']==a]['coordX'].iloc[w]\n",
    "            y0=df1[df1['seriesuid']==a]['coordY'].iloc[w]\n",
    "            z0=df1[df1['seriesuid']==a]['coordZ'].iloc[w]\n",
    "\n",
    "            v_x0=int(x0-X_org)\n",
    "            v_y0=int(y0-Y_org)\n",
    "            v_z0=int(z0-Z_org)\n",
    "            \n",
    "            for x in range(v_z0-radius-1, v_z0+radius+1):\n",
    "                for y in range(v_y0-radius-1, v_y0+radius+1):\n",
    "                    for z in range(v_x0-radius-1, v_x0+radius+1):\n",
    "                        deb = radius - abs(v_z0-x) - abs(v_y0-y) - abs(v_x0-z) \n",
    "                        if (deb)>=0:\n",
    "                            AA[x,y,z] = int(1)\n",
    "            \n",
    "        zzz=(size_split//2+1,size_split//2+1)\n",
    "        yyy=(size_split//2+1,size_split//2+1)\n",
    "        xxx=(size_split//2+1,size_split//2+1)\n",
    "        npad = (zzz,yyy,xxx)\n",
    "            \n",
    "        padded_mask = np.pad(AA, pad_width=npad, mode='constant', constant_values=int(0))\n",
    "        padded_array =np.pad(nda, pad_width=npad,mode='constant',constant_values=int(0))\n",
    "        \n",
    "        count_captured_image=0\n",
    "        #Crop region of interest\n",
    "        for w in range(0,sub_loop):\n",
    "            radius = int(df1[df1['seriesuid']==a]['diameter_mm'].iloc[w]/2)\n",
    "            x0=df1[df1['seriesuid']==a]['coordX'].iloc[w]\n",
    "            y0=df1[df1['seriesuid']==a]['coordY'].iloc[w]\n",
    "            z0=df1[df1['seriesuid']==a]['coordZ'].iloc[w]\n",
    "\n",
    "            v_x0=int(x0-X_org)+size_split//2+1\n",
    "            v_y0=int(y0-Y_org)+size_split//2+1\n",
    "            v_z0=int(z0-Z_org)+size_split//2+1\n",
    "            \n",
    "            #I don't know why i did this but it is fixing an error in loading files\n",
    "            if  not ((abs(v_z0)<32 and v_z0<0)  or (abs(v_y0)<32 and v_y0<0) or (abs(v_x0)<32 and v_x0<0)):\n",
    "                count_captured_image=count_captured_image+1\n",
    "                cropped_mask.append(padded_mask[v_z0-32:v_z0+32,v_y0-32:v_y0+32,v_x0-32:v_x0+32])\n",
    "                cropped_image.append(padded_array[v_z0-32:v_z0+32,v_y0-32:v_y0+32,v_x0-32:v_x0+32])\n",
    "                                                  \n",
    "        z_count=nda.shape[0]//size_split\n",
    "        y_count=nda.shape[1]//size_split\n",
    "        x_count=nda.shape[2]//size_split\n",
    "                        \n",
    "        #Capture some random empty slices from a scan\n",
    "        if count_captured_image<min_slices_per_batch:\n",
    "            select_count=(min_slices_per_batch-count_captured_image)//8+1\n",
    "            z_selected=random.sample(list(range(0,z_count)),select_count)\n",
    "            y_selected=random.sample(list(range(0,y_count)),select_count)\n",
    "            x_selected=random.sample(list(range(0,x_count)),select_count)\n",
    "            \n",
    "            for ip in range(0,z_count):\n",
    "                for jp in range(0,y_count):\n",
    "                    for kp in range(0,x_count):\n",
    "                        sum_pix=padded_mask[ip*size_split:(ip+1)*size_split,jp*size_split:(jp+1)*size_split,kp*size_split:(kp+1)*size_split].sum()\n",
    "                        if (ip in z_selected and jp in y_selected and kp in x_selected):\n",
    "                            cropped_mask.append(AA[ip*size_split:(ip+1)*size_split,jp*size_split:(jp+1)*size_split,kp*size_split:(kp+1)*size_split])\n",
    "                            cropped_image.append(nda[ip*size_split:(ip+1)*size_split,jp*size_split:(jp+1)*size_split,kp*size_split:(kp+1)*size_split])    \n",
    "                \n",
    "        AA=None\n",
    "        padded_array=None\n",
    "        nda=None\n",
    "        nda1=None\n",
    "        padded_mask=None\n",
    "        empty_mask=None\n",
    "        empty_array=None\n",
    "        nda0=None\n",
    "    \n",
    "    return cropped_image,cropped_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to batch generate images and related mask for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(files_path, batch_size,size_split,min_slices_per_batch):\n",
    "\n",
    "    LUF = len(files_path)\n",
    "\n",
    "    #this line is just to make the generator infinite, keras needs that    \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < LUF:\n",
    "            limit = min(batch_end, LUF)\n",
    "            X,Y = load_images(files_path,batch_start,limit,size_split,min_slices_per_batch)\n",
    "            X=np.asarray(X)\n",
    "            Y=np.asarray(Y)\n",
    "            data_X=X.reshape(X.shape[0],X.shape[1],X.shape[2],X.shape[3],1)\n",
    "            data_Y=Y.reshape(Y.shape[0],Y.shape[1],Y.shape[2],Y.shape[3],1)\n",
    "            \n",
    "            yield (data_X,data_Y) #a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to generate validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_data(file_list,start,end,size_split,min_slices_per_batch):\n",
    "    \n",
    "    cropped_image,cropped_mask=load_images(file_list,start,end,size_split,min_slices_per_batch)\n",
    "        \n",
    "    cropped_image=np.asarray(cropped_image)\n",
    "    data_X=cropped_image.reshape(cropped_image.shape[0],cropped_image.shape[1],cropped_image.shape[2],cropped_image.shape[3],1)\n",
    "\n",
    "    cropped_mask=np.asarray(cropped_mask)\n",
    "    data_Y=cropped_mask.reshape(cropped_mask.shape[0],cropped_mask.shape[1],cropped_mask.shape[2],cropped_mask.shape[3],1)\n",
    "    \n",
    "    return data_X,data_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_size=64\n",
    "number_of_slices_per_scan=12\n",
    "X,Y=valid_data(file_list=L,start=830,end=850,size_split=slice_size,min_slices_per_batch=number_of_slices_per_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 64, 64, 64, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 64, 64, 64, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting U-NET training...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dicom\n",
    "import os\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from skimage import measure, morphology\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv3D, MaxPooling3D, UpSampling3D, merge\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import SpatialDropout3D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numbers below gets divided everytime we apply maxpooling; this can create issue when concatenating two models\n",
    "NUM_SLIDES=64\n",
    "IMG_HEIGHT=64\n",
    "IMG_WIDTH=64\n",
    "IMG_CHANNELS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = .000000001\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.abs(K.sum(y_true_f * y_pred_f))\n",
    "    return (2. * intersection) / (K.abs(K.sum(y_true_f)) + K.abs(K.sum(y_pred_f)) + smooth)\n",
    "#Remove smooth from numerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_metric(y_true, y_pred):\n",
    "    smooth = .000000001\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.abs(K.sum(y_true_f * y_pred_f))\n",
    "    recall = (intersection) / (K.abs(K.sum(y_true_f)) + smooth)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 64, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 64, 64, 64, 1 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d_1 (SpatialDro (None, 64, 64, 64, 1 0           conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 64, 64, 64, 1 6928        spatial_dropout3d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 32, 32, 32, 1 0           conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 32, 1 64          max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 32, 32, 32, 3 13856       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d_2 (SpatialDro (None, 32, 32, 32, 3 0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 32, 32, 32, 3 27680       spatial_dropout3d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 16, 16, 16, 3 0           conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 16, 3 128         max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 16, 16, 16, 6 55360       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d_3 (SpatialDro (None, 16, 16, 16, 6 0           conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 16, 16, 16, 6 110656      spatial_dropout3d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 8, 8, 8, 64)  0           conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 8, 64)  256         max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 8, 8, 8, 128) 221312      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d_4 (SpatialDro (None, 8, 8, 8, 128) 0           conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 8, 8, 8, 128) 442496      spatial_dropout3d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3D)  (None, 4, 4, 4, 128) 0           conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 4, 128) 512         max_pooling3d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 4, 4, 4, 256) 884992      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d_5 (SpatialDro (None, 4, 4, 4, 256) 0           conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 4, 4, 4, 256) 1769728     spatial_dropout3d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3D)  (None, 2, 2, 2, 256) 0           conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2, 2, 2, 256) 1024        max_pooling3d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 2, 2, 2, 512) 3539456     batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d_6 (SpatialDro (None, 2, 2, 2, 512) 0           conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 2, 2, 2, 512) 7078400     spatial_dropout3d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 2, 2, 2, 512) 2048        conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTrans (None, 4, 4, 4, 256) 1048832     batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 4, 4, 512) 0           conv3d_transpose_1[0][0]         \n",
      "                                                                 conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 4, 4, 4, 256) 3539200     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d_7 (SpatialDro (None, 4, 4, 4, 256) 0           conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 4, 4, 4, 256) 1769728     spatial_dropout3d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 4, 4, 256) 1024        conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTrans (None, 8, 8, 8, 128) 262272      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 8, 256) 0           conv3d_transpose_2[0][0]         \n",
      "                                                                 conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 8, 8, 8, 128) 884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d_8 (SpatialDro (None, 8, 8, 8, 128) 0           conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 8, 8, 8, 128) 442496      spatial_dropout3d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 8, 128) 512         conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTrans (None, 16, 16, 16, 6 65600       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 16, 1 0           conv3d_transpose_3[0][0]         \n",
      "                                                                 conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 16, 16, 16, 6 221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d_9 (SpatialDro (None, 16, 16, 16, 6 0           conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 16, 16, 16, 6 110656      spatial_dropout3d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 16, 6 256         conv3d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_4 (Conv3DTrans (None, 32, 32, 32, 3 16416       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 32, 6 0           conv3d_transpose_4[0][0]         \n",
      "                                                                 conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, 32, 32, 32, 3 55328       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d_10 (SpatialDr (None, 32, 32, 32, 3 0           conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, 32, 32, 32, 3 27680       spatial_dropout3d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 32, 3 128         conv3d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_5 (Conv3DTrans (None, 64, 64, 64, 1 4112        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 64, 3 0           conv3d_transpose_5[0][0]         \n",
      "                                                                 conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)              (None, 64, 64, 64, 1 13840       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d_11 (SpatialDr (None, 64, 64, 64, 1 0           conv3d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_22 (Conv3D)              (None, 64, 64, 64, 1 6928        spatial_dropout3d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 64, 1 64          conv3d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_23 (Conv3D)              (None, 64, 64, 64, 1 17          batch_normalization_11[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 22,626,545\n",
      "Trainable params: 22,623,537\n",
      "Non-trainable params: 3,008\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build U-Net model\n",
    "inputs = keras.layers.Input((NUM_SLIDES,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "#s = keras.layers.Lambda(lambda x: x / 3095)(inputs)\n",
    " \n",
    "c1 = keras.layers.Conv3D(16, kernel_size=(3,3,3), activation='relu',padding='same')(inputs)\n",
    "c1 = keras.layers.SpatialDropout3D(0.3)(c1)\n",
    "c1 = keras.layers.Conv3D(16, (3,3,3), activation='relu',padding='same')(c1)\n",
    "#GlobalAveragePooling3D -- try this as well\n",
    "p1 = keras.layers.MaxPooling3D((2,2,2))(c1)\n",
    "p1 = BatchNormalization()(p1)\n",
    " \n",
    "c2 = keras.layers.Conv3D(32, (3,3,3), activation='relu',padding='same')(p1)\n",
    "c2 = keras.layers.SpatialDropout3D(0.3)(c2)\n",
    "c2 = keras.layers.Conv3D(32, (3,3,3), activation='relu',padding='same')(c2)\n",
    "p2 = keras.layers.MaxPooling3D((2,2,2))(c2)\n",
    "p2 = BatchNormalization()(p2)\n",
    "\n",
    "c3 = keras.layers.Conv3D(64, (3,3,3), activation='relu',padding='same')(p2)\n",
    "c3 = keras.layers.SpatialDropout3D(0.3)(c3)\n",
    "c3 = keras.layers.Conv3D(64, (3,3,3), activation='relu',padding='same')(c3)\n",
    "p3 = keras.layers.MaxPooling3D((2, 2,2))(c3)\n",
    "p3 = BatchNormalization()(p3)\n",
    "\n",
    "c4 = keras.layers.Conv3D(128, (3,3,3), activation='relu',padding='same')(p3)\n",
    "c4 = keras.layers.SpatialDropout3D(0.3)(c4)\n",
    "c4 = keras.layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(c4)\n",
    "p4 = keras.layers.MaxPooling3D(pool_size=(2,2,2))(c4)\n",
    "p4 = BatchNormalization()(p4)\n",
    "\n",
    "c5 = keras.layers.Conv3D(256, (3,3,3), activation='relu',padding='same')(p4)\n",
    "c5 = keras.layers.SpatialDropout3D(0.3)(c5)\n",
    "c5 = keras.layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(c5)\n",
    "p5 = keras.layers.MaxPooling3D(pool_size=(2,2,2))(c5)\n",
    "p5 = BatchNormalization()(p5)\n",
    "\n",
    "\n",
    "c55 = keras.layers.Conv3D(512, (3,3,3), activation='relu',padding='same')(p5)\n",
    "c55 = keras.layers.SpatialDropout3D(0.3)(c55)\n",
    "c55 = keras.layers.Conv3D(512, (3,3,3), activation='relu',padding='same')(c55)\n",
    "c55 = BatchNormalization()(c55)\n",
    "\n",
    "\n",
    "u66 = keras.layers.Conv3DTranspose(256, (2,2,2), strides=(2,2,2), padding='same')(c55)\n",
    "u66 = keras.layers.concatenate([u66, c5])\n",
    "c66 = keras.layers.Conv3D(256, (3,3,3), activation='relu',padding='same')(u66)\n",
    "c66 = keras.layers.SpatialDropout3D(0.3)(c66)\n",
    "c66 = keras.layers.Conv3D(256, (3,3,3), activation='relu',padding='same')(c66)\n",
    "c66 = BatchNormalization()(c66)\n",
    "\n",
    "u6 = keras.layers.Conv3DTranspose(128, (2,2,2), strides=(2,2,2), padding='same')(c66)\n",
    "u6 = keras.layers.concatenate([u6, c4])\n",
    "c6 = keras.layers.Conv3D(128, (3,3,3), activation='relu',padding='same')(u6)\n",
    "c6 = keras.layers.SpatialDropout3D(0.3)(c6)\n",
    "c6 = keras.layers.Conv3D(128, (3,3,3), activation='relu',padding='same')(c6)\n",
    "c6 = BatchNormalization()(c6)\n",
    "\n",
    "u7 = keras.layers.Conv3DTranspose(64, (2, 2,2), strides=(2, 2,2), padding='same')(c6)\n",
    "u7 = keras.layers.concatenate([u7, c3])\n",
    "c7 = keras.layers.Conv3D(64, (3, 3,3), activation='relu',padding='same')(u7)\n",
    "c7 = keras.layers.SpatialDropout3D(0.3)(c7)\n",
    "c7 = keras.layers.Conv3D(64, (3, 3,3), activation='relu',padding='same')(c7)\n",
    "c7 = BatchNormalization()(c7)\n",
    "\n",
    "u8 = keras.layers.Conv3DTranspose(32, (2, 2,2), strides=(2, 2,2), padding='same')(c7)\n",
    "u8 = keras.layers.concatenate([u8, c2])\n",
    "c8 = keras.layers.Conv3D(32, (3, 3,3), activation='relu',padding='same')(u8)\n",
    "c8 = keras.layers.SpatialDropout3D(0.3)(c8)\n",
    "c8 = keras.layers.Conv3D(32, (3, 3,3), activation='relu',padding='same')(c8)\n",
    "c8 = BatchNormalization()(c8)\n",
    "\n",
    "u9 = keras.layers.Conv3DTranspose(16, (2, 2,2), strides=(2, 2,2), padding='same')(c8)\n",
    "u9 = keras.layers.concatenate([u9, c1], axis=4)\n",
    "c9 = keras.layers.Conv3D(16, (3, 3,3), activation='relu',padding='same')(u9)\n",
    "c9 = keras.layers.SpatialDropout3D(0.3)(c9)\n",
    "c9 = keras.layers.Conv3D(16, (3, 3,3), activation='relu',padding='same')(c9)\n",
    "c9 = BatchNormalization()(c9)\n",
    " \n",
    "outputs = keras.layers.Conv3D(1, (1, 1,1), activation='sigmoid')(c9)\n",
    " \n",
    "model = keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss=dice_coef_loss, metrics=[dice_coef,recall_metric])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('temp_model.h5', custom_objects={'dice_coef_loss': dice_coef_loss,'dice_coef':dice_coef,'recall_metric':recall_metric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "551/820 [===================>..........] - ETA: 1:15:50 - loss: -0.0015 - dice_coef: 0.0015 - recall_metric: 0.7811"
     ]
    }
   ],
   "source": [
    "batch_size=1\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('temp_model.h5', save_weights_only=False)\n",
    "model.fit_generator(image_generator(files_path=new_train_data,batch_size=batch_size,size_split=slice_size,min_slices_per_batch=number_of_slices_per_scan),steps_per_epoch=len(new_train_data)//batch_size,epochs=100,validation_data=(X,Y),verbose=1,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_refined_dice_10_100.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
